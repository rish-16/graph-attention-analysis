{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f527d905-8b41-4c62-940c-37cba7b9a06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric as tg\n",
    "import torch_geometric.nn as tgnn\n",
    "from torch_geometric.utils import get_laplacian, to_dense_adj\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83a6e6b7-79ac-4595-a4b6-ee61d03fc047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_gammas(X, adjlist, a1, a2, b):\n",
    "    inter_gammas_gat = [[[],[]],[[],[]]]\n",
    "    intra_gammas_gat  = [[[],[]],[[],[]]]\n",
    "\n",
    "    pairs_intra = 0\n",
    "    pairs_inter = 0\n",
    "\n",
    "    n_intra = 0\n",
    "    n_inter = 0\n",
    "\n",
    "    N = int(len(X)/2)\n",
    "    x_mlp_gat = np.zeros(len(X))\n",
    "    x_gat = np.zeros(len(X))\n",
    "    x_gcn = np.zeros(len(X))\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        gamma_gat_head1 = gamma_gat_fn(X[i], X[adjlist[i]], a1, a2, b)\n",
    "        gamma_gat_head2 = gamma_gat_fn(X[i], X[adjlist[i]], -a1, -a2, -b)\n",
    "        gamma_gcn = np.ones(len(adjlist[i]))/len(adjlist[i])\n",
    "        \n",
    "        x_gat[i] = np.dot(gamma_gat_head1, X[adjlist[i]]) + np.dot(gamma_gat_head2, X[adjlist[i]])\n",
    "        x_gcn[i] = np.dot(gamma_gcn, X[adjlist[i]])\n",
    "        \n",
    "        ct = 0\n",
    "        for j in adjlist[i]:\n",
    "            if (j < N and i < N) or (j >= N and i >= N):\n",
    "                pairs_intra += pairs_mlp_gat[ct] > 0\n",
    "                \n",
    "                if (j < N and i < N):\n",
    "                    intra_gammas_gat[0][0].append(gamma_gat_head1[ct])\n",
    "                    intra_gammas_gat[1][0].append(gamma_gat_head2[ct])\n",
    "                else:\n",
    "                    intra_gammas_gat[0][1].append(gamma_gat_head1[ct])\n",
    "                    intra_gammas_gat[1][1].append(gamma_gat_head2[ct])\n",
    "                n_intra += 1\n",
    "            elif (j < N and i >= N) or (j >= N and i < N):\n",
    "                pairs_inter += pairs_mlp_gat[ct] <= 0\n",
    "                if (j < N and i >= N):\n",
    "                    inter_gammas_gat[0][0].append(gamma_gat_head1[ct])\n",
    "                    inter_gammas_gat[1][0].append(gamma_gat_head2[ct])\n",
    "                else:\n",
    "                    inter_gammas_gat[0][1].append(gamma_gat_head1[ct])\n",
    "                    inter_gammas_gat[1][1].append(gamma_gat_head2[ct])                   \n",
    "                n_inter += 1\n",
    "            ct += 1\n",
    "            \n",
    "    class_pair_intra = pairs_intra/n_intra\n",
    "    class_pair_inter = pairs_inter/n_inter\n",
    "            \n",
    "    return x_gat, x_gcn, class_pair_intra, class_pair_inter, intra_gammas_gat, inter_gammas_gat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ba72acd-2f8c-45b9-995e-b5f2d7a89a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "torch.Size([2, 299038])\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "d = int(np.ceil(n/(np.log(n)**2)))\n",
    "p = 0.5\n",
    "q = 0.1\n",
    "heads = 2 # does not work for another number\n",
    "\n",
    "sizes = [int(n/2), int(n/2)]\n",
    "probs = [[p,q], [q,p]]\n",
    "\n",
    "std_ = 0.1\n",
    "mu_up = 20*std_*np.sqrt(np.log(n**2))/(2*np.sqrt(d))\n",
    "mu_lb = 0.01*std_/(2*np.sqrt(d))\n",
    "\n",
    "mus = np.geomspace(mu_lb, mu_up, 30, endpoint=True)\n",
    "ground_truth = np.concatenate((np.zeros(int(n/2)), np.ones(int(n/2))))\n",
    "\n",
    "# for mu in mus:\n",
    "g = nx.stochastic_block_model(sizes, probs)\n",
    "\n",
    "mu = mus[0]\n",
    "adjlist = [[v for v in g.neighbors(i)] for i in range(n)]\n",
    "adj_matrix = [[0 for i in range(n)] for j in range(n)]\n",
    "for i in range(n):\n",
    "    nbors = g.neighbors(i)\n",
    "    for j in nbors:\n",
    "        adj_matrix[i][j] = 1\n",
    "        \n",
    "edge_idx, _ = tg.utils.dense_to_sparse(torch.from_numpy(np.array(adj_matrix)))\n",
    "\n",
    "for i in range(len(adjlist)):\n",
    "    adjlist[i].append(i)\n",
    "\n",
    "X = np.zeros((n,d))\n",
    "X[:int(n/2)] = -mu\n",
    "X[int(n/2):] = mu\n",
    "noise = std_*np.random.randn(n,d)\n",
    "X = X + noise\n",
    "\n",
    "R = 1\n",
    "mu_ = mu*np.ones(d)\n",
    "w = (R/np.linalg.norm(mu_))*mu_\n",
    "Xw = X@w\n",
    "\n",
    "print (Xw.shape)\n",
    "print (edge_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4abf4a7a-d5db-4975-8041-72195c642a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eigen(nn.Module):\n",
    "    def __init__(self, k):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "    \n",
    "    def forward(self, edge_idx):\n",
    "        lap_idx, lap_wt = get_laplacian(edge_idx, normalization=\"sym\")\n",
    "        lap_adj = to_dense_adj(lap_idx)\n",
    "        eigenvals, eigenvecs = torch.linalg.eig(lap_adj)\n",
    "        top_eig = eigenvecs.squeeze(0)[:, 1:self.k+1]\n",
    "        top_eig = torch.real(top_eig)\n",
    "        new_edge_features = torch.Tensor(edge_idx.size(1), 2 * self.k)\n",
    "        new_edge_idx = edge_idx.T\n",
    "\n",
    "        for idx, pair in enumerate(new_edge_idx):\n",
    "            i, j = pair\n",
    "            x_i_prime = top_eig[i]\n",
    "            x_j_prime = top_eig[j]\n",
    "            new_feat = torch.cat([x_i_prime, x_j_prime], dim=0)\n",
    "            new_edge_features[idx] = new_feat\n",
    "\n",
    "        return new_edge_features\n",
    "\n",
    "class GATv3Layer(tgnn.MessagePassing):\n",
    "    def __init__(self, indim, eigendim, outdim):\n",
    "        super().__init__(aggr=\"add\")\n",
    "        self.original_mlp = nn.Sequential(\n",
    "                nn.Linear(2 * indim, outdim), # account for extra Wx_i || Wx_j from GATv1\n",
    "                nn.Linear(outdim, outdim),\n",
    "                nn.LeakyReLU(0.02),\n",
    "                nn.Linear(outdim, outdim)\n",
    "            )\n",
    "        \n",
    "        self.eigen_mlp = nn.Sequential(\n",
    "                nn.Linear(eigendim, outdim), # account for the fact that edge attributes are already concatenated\n",
    "                nn.Linear(outdim, outdim),\n",
    "                nn.LeakyReLU(0.02),\n",
    "                nn.Linear(outdim, outdim)\n",
    "            )\n",
    "        self.W = nn.Linear(indim, indim)\n",
    "        self.out = nn.Linear(indim, outdim)\n",
    "\n",
    "        self.alpha = nn.Parameter(torch.rand(1, 1))\n",
    "        nn.init.xavier_uniform_(self.alpha.data, gain=1.414)\n",
    "\n",
    "        self.beta = nn.Parameter(torch.rand(1, 1))\n",
    "        nn.init.xavier_uniform_(self.beta.data, gain=1.414)\n",
    "        \n",
    "        gamma = self._gamma\n",
    "        pair_pred = self._pair_pred\n",
    "        self._gamma = None\n",
    "        self._pair_pred = None\n",
    "        \n",
    "    def forward(self, x, edge_attr, edge_idx):\n",
    "        edge_idx, edge_attr = tg.utils.add_self_loops(edge_idx, edge_attr)\n",
    "        return self.propagate(edge_idx, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        cat = torch.cat([x_i, x_j], dim=1)\n",
    "        \n",
    "        node_attr = self.alpha * self.original_mlp(cat)\n",
    "        edge_attr = self.beta * self.eigen_mlp(edge_attr)\n",
    "        \n",
    "        self._pair_pred = F.leaky_relu(node_attr + edge_attr),\n",
    "        gamma = torch.softmax(F.leaky_relu(node_attr + edge_attr), 1)\n",
    "        msg = gamma * self.out(x_j)\n",
    "        \n",
    "        return msg\n",
    "\n",
    "class GATv3(nn.Module):\n",
    "    def __init__(self, indim, eigendim, hidden, outdim, k):\n",
    "        super().__init__()\n",
    "\n",
    "        self.eigen = Eigen(k)\n",
    "        self.gat1 = GATv3Layer(indim, eigendim, hidden)\n",
    "        self.gat2 = GATv3Layer(hidden, eigendim, outdim)\n",
    "\n",
    "    def forward(self, x, edge_idx):\n",
    "        with torch.no_grad():\n",
    "            eigen_x = self.eigen(edge_idx)\n",
    "        x = torch.relu(self.gat1(x, eigen_x, edge_idx))\n",
    "        out = torch.softmax(self.gat2(x, eigen_x, edge_idx), 1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db4fd576-78eb-47fa-bb31-e1f3107dd67a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got -2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m gat \u001b[38;5;241m=\u001b[39m GATv3(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m Xw_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(Xw)\n\u001b[0;32m----> 3\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mgat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXw_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m (y\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/PyG/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36mGATv3.forward\u001b[0;34m(self, x, edge_idx)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     74\u001b[0m     eigen_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meigen(edge_idx)\n\u001b[0;32m---> 75\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgat1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meigen_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_idx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     76\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgat2(x, eigen_x, edge_idx), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/PyG/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36mGATv3Layer.forward\u001b[0;34m(self, x, edge_attr, edge_idx)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_attr, edge_idx):\n\u001b[1;32m     50\u001b[0m     edge_idx, edge_attr \u001b[38;5;241m=\u001b[39m tg\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39madd_self_loops(edge_idx, edge_attr)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/PyG/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:309\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m decomp_args:\n\u001b[1;32m    307\u001b[0m         kwargs[arg] \u001b[38;5;241m=\u001b[39m decomp_kwargs[arg][i]\n\u001b[0;32m--> 309\u001b[0m coll_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__collect__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__user_args__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                             \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m msg_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minspector\u001b[38;5;241m.\u001b[39mdistribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m, coll_dict)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/PyG/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:201\u001b[0m, in \u001b[0;36mMessagePassing.__collect__\u001b[0;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     data \u001b[38;5;241m=\u001b[39m data[dim]\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__set_size__\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__lift__(data, edge_index, dim)\n\u001b[1;32m    204\u001b[0m out[arg] \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/PyG/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:163\u001b[0m, in \u001b[0;36mMessagePassing.__set_size__\u001b[0;34m(self, size, dim, src)\u001b[0m\n\u001b[1;32m    161\u001b[0m the_size \u001b[38;5;241m=\u001b[39m size[dim]\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m the_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     size[dim] \u001b[38;5;241m=\u001b[39m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m the_size \u001b[38;5;241m!=\u001b[39m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim):\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    166\u001b[0m         (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEncountered tensor with size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    167\u001b[0m          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but expected size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthe_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got -2)"
     ]
    }
   ],
   "source": [
    "gat = GATv3(1, 1, 1, 1, 1)\n",
    "Xw_tensor = torch.from_numpy(Xw)\n",
    "y = gat(Xw_tensor, edge_idx)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36834fd4-c75c-4964-b0fb-1ae08f60dbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
